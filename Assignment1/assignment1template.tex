\documentclass[11pt]{article}

\usepackage{fullpage, verbatim,amsthm,amsmath,amssymb,amsfonts}

\parindent 0pt
\parskip 3mm

\theoremstyle{definition}
\newtheorem*{solution}{Solution}

\begin{document}

	\begin{center}
		{\bf \Large CPSC 418 / MATH 318 --- Introduction to Cryptography
		
		ASSIGNMENT 1 %--- SOLUTION KEY
		}
	\end{center}
	
	\hrule 	
	
	\textbf{Name:} Hanum Lee  \\
	\textbf{Student ID:} 30010205\ 
	
	\medskip \hrule
	
	\begin{enumerate}
	
		\item[] \textbf{Problem 1} --- Superencipherment for substitution ciphers, 12 marks
	
	\begin{enumerate}
		\item
		\begin{enumerate}
			\item Single Cipher: $E_{k}(M) \equiv M + K \pmod{26}$\\
				Double Cipher:\\
				\[E_{K_{1}}(E_{K_{2}}(M)) \equiv E_{K_{1}}(M+K_{2}\pmod{26})\]
				\[= M + K_{2}\pmod{26} + K_{1}\pmod{26}\]
				\[= M + K_{3}\pmod{26}\]
				for $K_{1,2,3} \in Keyspace$
			\item Assume: $E_{k}(m) \equiv m + k\pmod{26}$ For all $m \in \mathcal{M} \& k \in \mathcal{K}$\\
			Base case: $E_{K_{1}}(E_{K_{2}}(M)) \equiv  M + K_{3}\pmod{26}$ (Proven at 1.(a).i)\\
			Inductive Hypothesis: $E_{k_{n}}(E_{k_{n-1}}...E_{k_{1}}(m)) \equiv m + (k_{n+n-1+...+1} ) \pmod{26}$ is true for $n > 2 $\\
			Inductive Step:\\
			Want to show that: $E_{k_{n+1}}(E_{k_{n}}...E_{k_{1}}(m)) \equiv m + k_{(n+1)+n+..+1} \pmod{26}$\\
			$E_{k_{n+1}}(E_{k_{n}}...E_{k_{1}}(m)) = E_{k_{k+1}}(m+k_{n+...+1}\pmod{26})$ (with Inductive Hypothesis)
			\[\equiv m + k_{(n+1) + n + .. +1} \pmod{26} \] where $k_{(n+1) + n+...+1} = k_q$ for $q \in \mathbb{Z} $\\
			Therefore, the induction holds true.
		\end{enumerate}
		\item
		The length of new keyword $w$ is least common multiple of the length two words $m$ and $n$. Since Vigenere Cipher is a shift cipher to each character with the key as the characters in key word, $V_{k_{1}}(V_{k_{2}}(m)) = V_{k_{1} + k_{2}}(M)$.
		To find the new keyword $w$, use the shorter word between $w_{1}$ and $w_{2}$ as key for the other one and apply Vigenere Cipher to it.
	\end{enumerate}
	
		\newpage
		\item[] \textbf{Problem 2} --- Key size versus password size, 21 marks]
	
	
	
	\begin{enumerate}
		\item $2^{7}*2^{7}*2^{7}*2^{7}*2^{7}*2^{7}*2^{7}2^{7} = 2^{7*8} = 2^{56}$
		\item
		
		\begin{enumerate}
			\item $98*98*98*98*98*98*98*98 = 98^{8}$
			\item$\dfrac{98^8}{2^{56}} * 100 = 11.81\%$
		\end{enumerate}
		
		\item $H(X) = {\sum}_{i=0}^{n} p(X_{i}) \log_{2} \dfrac{1}{p(X_{i})}$\\
		In this case:\\
		$H(X) = 8 * {\sum}_{i=1}^{n} \dfrac{1}{n} \log_{2} n$ (Since all characters have equal chance of appearing for each character and there are 8 characters in passwords )\\
		$= 8 * \log_{2} 94$\\
		$ = 52.43$
		
		\item Similar as above\\
		$H(X) = 8 * {\sum}_{i=1}^{n} \dfrac{1}{n} \log_{2} n$\\
		$= 8 * \log_{2} 26$\\
		$= 37.60$

		\item
		\begin{enumerate}
			\item $128 = l * \log_{2} 94 $ where $l$ is length of the password\\ 
			$l = \dfrac{128}{\log_{2} 94}$\\
			$l = 19.35$\\
			So, at least 20 characters
			
			\item $128 = l * \log_{2} 26 $ where $l$ is length of the password\\
			$l = \dfrac{128}{\log_{2} 26}$\\
			$l = 27.23$\\
			So, at least 28 characters
			
		\end{enumerate}
	\end{enumerate}
	
	
	\newpage
	\item[] \textbf{Problem 3} --- Equiprobability maximizes entropy for two outcomes, 12 marks
	
	
	\begin{enumerate}
		\item 
		$H(X) = p(X_{1}) \log_{2}(\dfrac{1}{p(X_{1})}) + p(X_{2})\log_{2}(\dfrac{1}{p(X_{2})})$\\
		$= \dfrac{1}{4} \log_{2} 4 + \dfrac{3}{4} \log_{2} \dfrac{4}{3}$\\
		$= \dfrac{1}{2} + 0.311$\\
		$= 0.81$
		\item To find maximum of a function, first, we need to find derivative of the function.\\
		$\dfrac{d}{dp} -p \log_{2}(p)-(1-p)log_{2}(1-p)$\\
		$ = \dfrac{d}{dp}(- p \dfrac{\log p}{\log 2} - (1-p)\dfrac{\log (1-p)}{\log 2} )$ (Using product law and identity)\\
		$ = -(\dfrac{p}{p}+\dfrac{\log p}{\log 2}) - (\dfrac{(1-p)}{(1-p)} + \dfrac{\log (1-p)}{\log 2}) $\\
		$ = -1 - \dfrac{\log p}{\log 2} + 1 + \dfrac{\log (1-p)}{\log 2}$\\
		$ = \dfrac{\log(1-p)-\log(p)}{\log 2}$\\
		Then we find the $p$ value when the equation above is equal to $0$ which is $p=\dfrac{1}{2}$, therefore, it shows that entropy is maximal when both outcomes are equally likely.
		
		
		
		\item  Since we know the value $p$, we just substitute it to the equation given.\\
		$H(X) = \dfrac{1}{2} \log_{2}(2) + (\dfrac{1}{2}) \log_{2}(2) = 1$\\
		So maximal value of $H(X)$ is $1$.	
	\end{enumerate}
	
	\newpage
	\item[] \textbf{Problem 4} --- Conditional entropy, 12 marks
		
		\begin{enumerate}
			\item To find $H(M|C)$, I have to compute:\\
			$\sum_{i=1}^{4}p(C_{i}) \sum_{j=1}^{4} p(C_{i}|M_{j})\log_{2}(\dfrac{1}{p(C_{i}|M_{j})})$\\
			For $p(C_{1})$, $\sum_{j=1}^{4} p(C_{1}|M_{j})\log_{2}(\dfrac{1}{p(C_{1}|M_{j})}) = \dfrac{1}{2} \log_{2} 2 + \dfrac{1}{2} \log_{2} 2 + 0 + 0 = 1$ Assuming that $M_{1}$ and $M_{2}$ has equal chance of appearing when cipher text is $C_{1}$\\
			Repeat this for $p(C_{2}),p(C_{3}),p(C_{4})$\\
			For $p(C_{2})$, $\sum_{j=2}^{4} p(C_{2}|M_{j})\log_{2}(\dfrac{1}{p(C_{2}|M_{j})}) = 0 + 0  + \dfrac{1}{2} \log_{2} 2 + \dfrac{1}{2} \log_{2} 2 = 1$\\
			This goes same for  $p(C_{3}),p(C_{4})$,\\
			So, $\sum_{i=1}^{4}p(C_{i}) \sum_{j=1}^{4} p(C_{i}|M_{j})\log_{2}(\dfrac{1}{p(C_{i}|M_{j})}) = 4$
			\item If cryptosystem is providing perfect secrecy implies that knowing the ciphertext $\mathcal{C}$ gives no information about $\mathcal{M}$.Which could also means that knowing message does not give information about ciphertext. This can be represented as
			$H(\mathcal{C}|\mathcal{M}) = H(\mathcal{C})$.\\
			Then, $H(C|M) = \dfrac{p(C)p(M|C)}{p(M)}$\\
			For $H(\mathcal{C}|\mathcal{M}) = H(\mathcal{C})$ to hold true,  $H(\mathcal{M}|\mathcal{C}) = H(\mathcal{M})$ has to hold true.\\
			Therefore, for cryptosystem to have perfect secrecy, $H(\mathcal{M}|\mathcal{C}) = H(\mathcal{M})$ has to hold true.
			
			%With the method used above, we can find $H(C|M)$ and $H(C)$\\
			%\[H(C|M) = \sum_{i=1}^{4}p(M_{i}) \sum_{j=1}^{4} p(M_{i}|C_{j})\log_{2}(\dfrac{1}{p(M_{i}|C_{j})})\]
%			Since all of the $M \in \mathcal{M}$ has equal possibility, I just have to compute one of them.\\
%			For $p(M_{1})$, $\sum_{j=1}^{4} p(M_{1}|C_{j})\log_{2}(\dfrac{1}{p(M_{1}|C_{j})}) = \dfrac{1}{2} \log_{2} 2 + 0 + 0 + \dfrac{1}{2} \log_{2} 2 = 1$\\
%			So, $H(C|M) = 4 $ and $H(C) = 4$
			
			\item No, 
			With the methods used above, we can find $H(C|M)$ and $H(C)$\\
			\[H(C|M) = \sum_{i=1}^{4}p(M_{i}) \sum_{j=1}^{4} p(M_{i}|C_{j})\log_{2}(\dfrac{1}{p(M_{i}|C_{j})})\]
			Since all of the $M \in \mathcal{M}$ has equal possibility, I just have to compute one of them.\\
			For $p(M_{1})$, $\sum_{j=1}^{4} p(M_{1}|C_{j})\log_{2}(\dfrac{1}{p(M_{1}|C_{j})}) = \dfrac{1}{2} \log_{2} 2 + 0 + 0 + \dfrac{1}{2} \log_{2} 2 = 1$\\
			So, $H(C|M) = 4 $ and $H(C) = 8$\\
			Since, $H(\mathcal{C}|\mathcal{M}) \ne H(\mathcal{C})$, example does not provide perfect secrecy.
			
		\end{enumerate}
	\end{enumerate}
	
	


\end{document}
